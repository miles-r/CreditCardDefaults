{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Credit Card Defaults\n",
    "\n",
    "This notebook compares four common classification algorithms individually and in ensemble for their accuracy in predicting credit card defaults using ROC as a selection metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdefaults = pd.read_parquet(\"CCDefaults.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccdefaults.var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ccdefaults[\"default_oct\"]\n",
    "other_targets = ccdefaults[[\"avg_bill_3\", \"percentile_bin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdefaults.groupby(\"percentile_bin\").median()[\"avg_bill\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ccdefaults.drop(columns = [\"default_oct\", \"avg_bill_3\", \"percentile_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy = \"stratified\")\n",
    "\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "dummy_pr = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true, pred, name):\n",
    "    scores = {\"Model\":[], \"ROC_AUC\": [], \"F1\": [], \"Brier\": []}\n",
    "    scores[\"Model\"].append(name)\n",
    "    scores[\"ROC_AUC\"].append(metrics.roc_auc_score(true, pred))\n",
    "    scores[\"F1\"].append(metrics.f1_score(true, pred))\n",
    "    #scores[\"Brier\"].append(metrics.brier_score_loss(true, pred))\n",
    "    return pd.DataFrame(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(get_metrics(y_test, dummy_pr, \"Dummy Classifier\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "scores = scores.append(get_metrics(y_test, lr_pred, \"Logit\"), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(np.power(10.0, np.arange(-4, 4)))\n",
    "\n",
    "lr_lasso = LogisticRegressionCV(penalty='l1'\n",
    "                                , Cs = lambdas\n",
    "                                , solver = 'liblinear'\n",
    "                                , cv = 5).fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_lasso_pred = lr_lasso.predict(X_test_scaled)\n",
    "scores = scores.append(get_metrics(y_test, lr_lasso_pred, \"Logit Lasso\"), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame(lr_lasso.coef_, columns=X_train.columns)\n",
    "lasso_coefs[lasso_coefs != 0].dropna(axis = \"columns\").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = { \"n_estimators\": np.arange(15, 60, step = 15)\n",
    "          , \"max_depth\": np.arange(1, 20)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_gs = GridSearchCV(rf, rf_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_gs.best_estimator_.predict(X_test)\n",
    "\n",
    "scores = scores.append(get_metrics(y_test, rf_pred, \"Random Forest\"), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_scaled.shape[0]/(3*(X_train_scaled.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = keras.Sequential([\n",
    "    keras.layers.Dense(180, activation = \"relu\", input_shape = (X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(180, activation = \"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(360, activation = \"relu\"),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\"),\n",
    "]\n",
    ")\n",
    "\n",
    "nnet.summary()\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.AUC(name=\"AUC\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\")\n",
    "]\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"ccdefaults_checkpoint_{epoch}.h5\")]\n",
    "\n",
    "nnet.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = nnet.fit(X_train_scaled,\n",
    "         y_train,\n",
    "         batch_size=2048,\n",
    "         epochs = 30,\n",
    "         validation_data=(X_test_scaled, y_test),\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(epochs.history[\"val_AUC\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_eval = nnet.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.append(\n",
    "    pd.DataFrame(\n",
    "        {\"Model\":[\"Neural Network\"], \n",
    "         \"ROC_AUC\": [nnet_eval[1]],\n",
    "         \"F1\": [2*(nnet_eval[6]*nnet_eval[7])/(nnet_eval[6]+nnet_eval[7])],\n",
    "         \"Balanced Accuracy\": [round(nnet_eval[1], 4)]]}), ignore_index= True)\n",
    "\n",
    "#\"Brier\": [((nnet_pred - y_test.to_numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the Neural Network approach is the most accurate, but who cares? Find out in the enrapturing conclusion to the CCDefaults saga in:\n",
    "\n",
    "[Credit Card Defaults 2: Tokyo Drift!](CCDefaults_FinancialProjections.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
